{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Spacy \n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from spacy import displacy\n",
    "\n",
    "#import Utils\n",
    "from utils import get_corpus_dataframe\n",
    "\n",
    "from IPython.display import HTML\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_md')\n",
    "\n",
    "# Load data \n",
    "# Import Dataset into a Pandas Dataframe\n",
    "df = get_corpus_dataframe(eu_only=False)\n",
    "\n",
    "with open(\"data_ready.sav\", \"rb\") as fp:   # Unpickling\n",
    "    data_ready = pickle.load(fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country\n",
       "china          On July , Chinas State Council issued a semin...\n",
       "denmark        National Strategy for Artificial Intelligence...\n",
       "finland        How can we ensure that Finland becomes one of...\n",
       "france         FOR A MEANINGFUL ARTIFICIAL INTELLIGENCE TOWA...\n",
       "germany       Artificial Intelligence Strategy Status: Novem...\n",
       "india         Discussion Paper National Strategy for Artific...\n",
       "italy         ai.italia.it #AItaskforce ARTIFICIAL INTELLIGE...\n",
       "japan          Artificial Intelligence Technology Strategy (...\n",
       "luxembourg    Artificial Intelligence: a strategic vision fo...\n",
       "mexico        TOWARDS AN AI STRATEGY IN MEXICO: Harnessing t...\n",
       "sweden        National approach to artificial intelligence I...\n",
       "uk             GOV.UK . Home ( . Artificial Intelligence Sec...\n",
       "Name: clean_content, dtype: object"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.clean_content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.iloc[0].clean_content\n",
    "\n",
    "text = text.lower().replace('\\n', ' ').replace('\\t', ' ').replace('\\xa0',' ')\n",
    "text = ' '.join(text.split())\n",
    "doc = nlp(text)\n",
    "\n",
    "sentences = []\n",
    "for i in doc.sents:\n",
    "  if len(i)>1:\n",
    "    sentences.append(i.string.strip())\n",
    "    \n",
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = embed(\n",
    "    sentences,\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"default\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  sess.run(tf.tables_initializer())\n",
    "  x = sess.run(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#@title Sementic search\n",
    "#@markdown Enter a set of words to find matching sentences. 'results_returned' can beused to modify the number of matching sentences retured. To view the code behind this cell, use the menu in the top right to unhide...\n",
    "search_string = \"code of ethics\" #@param {type:\"string\"}\n",
    "results_returned = \"3\" #@param [1, 2, 3]\n",
    "\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "\n",
    "embeddings2 = embed(\n",
    "    [search_string],\n",
    "    signature=\"default\",\n",
    "    as_dict=True)[\"default\"]\n",
    "\n",
    "with tf.Session() as sess:\n",
    "  sess.run(tf.global_variables_initializer())\n",
    "  sess.run(tf.tables_initializer())\n",
    "  search_vect = sess.run(embeddings2)\n",
    "  \n",
    "\n",
    "cosine_similarities = pd.Series(cosine_similarity(search_vect, x).flatten())\n",
    "output =\"\"\n",
    "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
    "  output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
    "  for i in sentences[i].split():\n",
    "    if i.lower() in search_string:\n",
    "      output += \" <b>\"+str(i)+\"</b>\"\n",
    "    else:\n",
    "      output += \" \"+str(i)\n",
    "  output += \"</p><hr>\"\n",
    "    \n",
    "output = '<h3>Results:</h3>'+output\n",
    "display(HTML(output))\n",
    "#   print(sentences[i])\n",
    "#   print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brainwaves]",
   "language": "python",
   "name": "conda-env-brainwaves-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
