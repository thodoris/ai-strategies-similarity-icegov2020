{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import string\n",
    "import math\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# Spacy \n",
    "import spacy\n",
    "#from spacy.lang.en import English\n",
    "#from spacy import displacy\n",
    "\n",
    "# sklearn\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "#import Utils\n",
    "from utils import get_corpus_dataframe\n",
    "\n",
    "from IPython.display import HTML\n",
    "import logging\n",
    "logging.getLogger('tensorflow').disabled = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retireve sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sentences(save_as_filename):\n",
    "    \n",
    "    nlp = spacy.load('en_core_web_md')\n",
    "    nlp.max_length = 1520000\n",
    "    MAX_WORDS_IN_SENTENCE = 80\n",
    "    MIN_WORDS_IN_SENTENCE = 3\n",
    "    punctuation = '!\"#$%&()*+:;<=>?@[\\\\]^_`{|}~‚óè'\n",
    "    # Load data \n",
    "    # Import Dataset into a Pandas Dataframe\n",
    "    df = get_corpus_dataframe(eu_only=False)\n",
    "\n",
    "    ## Clean Text\n",
    "    # remove punctuation \n",
    "    df['clean_content'] = df['clean_content'].apply(lambda x: ''.join(ch for ch in x if ch not in set(punctuation)))\n",
    "\n",
    "    # convert text to lowercase\n",
    "    df['clean_content'] = df['clean_content'].str.lower()\n",
    "\n",
    "    ## Load Sentences\n",
    "    sentences = [sent.string.strip() for text in df.clean_content.tolist() for sent in nlp(text).sents if len(sent) in range(MIN_WORDS_IN_SENTENCE,MAX_WORDS_IN_SENTENCE)]\n",
    "\n",
    "    #save \n",
    "    if (save_as_filename):\n",
    "        with open(save_as_filename, \"wb\") as fp:   #Pickling\n",
    "            pickle.dump(sentences, fp)\n",
    "    \n",
    "    return sentences\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "elmo_sentences_filename ='./preprocessed_text/elmo_sentences.sav'\n",
    "if os.path.isfile(elmo_sentences_filename):\n",
    "    with open(elmo_sentences_filename, \"rb\") as fp:   # Unpickling\n",
    "        sentences = pickle.load(fp)\n",
    "else:\n",
    "    # Create sentences\n",
    "    sentences = create_sentences(save_as_filename=elmo_sentences_filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Sentence Embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9201\n"
     ]
    }
   ],
   "source": [
    "print(len(sentences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # calculate embeddings via tfhub\n",
    "url = \"https://tfhub.dev/google/elmo/3\"\n",
    "elmo = hub.load(url)\n",
    "\n",
    "def elmo_vectors(x):\n",
    "    tensor_list = tf.convert_to_tensor(x)\n",
    "    embeddings = elmo.signatures['default'](tensor_list)[\"default\"]\n",
    "    return embeddings\n",
    "        \n",
    "\n",
    "# function to return the elmo embeddings\n",
    "def get_sentences_vectors():\n",
    "    \n",
    "    elmo_embeddings_filename ='./saved_state/elmo_embeddings.pkl'\n",
    "    # check if the embeddings are already available in pickle file\n",
    "    if os.path.isfile(elmo_embeddings_filename):\n",
    "        with open(elmo_embeddings_filename, \"rb\") as fp:   # Unpickling\n",
    "            sentences_embeddings = pickle.load(fp)\n",
    "    else:\n",
    "       \n",
    "        # split in batches of 500\n",
    "        list_batch_sentences = [sentences[i:i+500] for i in range(0,len(sentences),500)]\n",
    "\n",
    "        # Extract ELMo embeddings\n",
    "        elmo_embeddings = [elmo_vectors(x) for x in list_batch_sentences]\n",
    "\n",
    "        # concentrate ELMo embeddings\n",
    "        #flatten the lists\n",
    "        sentences_embeddings = [y for x in elmo_embeddings for y in x]\n",
    "\n",
    "        # pickle\n",
    "        with open(elmo_embeddings_filename, \"wb\") as fp:   #Pickling\n",
    "            pickle.dump(sentences_embeddings, fp)\n",
    "    \n",
    "    return sentences_embeddings\n",
    "\n",
    "sentences_vectors = get_sentences_vectors()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Similarity calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 12min 50s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "#search_term='code of ethics' # param\n",
    "search_term='skills and education'\n",
    "embeddings_search_vectors = elmo.signatures['default'](tf.convert_to_tensor([search_term]))['default']\n",
    "\n",
    "cosine_similarities = pd.Series(cosine_similarity(embeddings_search_vectors,sentences_vectors).flatten())\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<h3>Results:</h3><p style=\"font-family:verdana; font-size:110%;\">  especially cooperation <b>between</b> <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors will <b>be</b> critical.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  area of <b>collaboration</b> <b>between</b> <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors is that of procurement.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  this will allow <b>and</b> ensure fair <b>and</b> equitable data sharing <b>between</b> organisations in <b>the</b> <b>private</b> sector, <b>and</b> <b>between</b> <b>the</b> <b>private</b> <b>and</b> <b>public</b> sectors.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> best way <b>to</b> gain access <b>to</b> these is via public-private partnerships, in other words, via cooperation <b>between</b> <b>the</b> <b>private</b> <b>and</b> <b>public</b> sectors.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  cooperation will <b>be</b> needed <b>between</b> <b>the</b> <b>private</b> <b>and</b> <b>public</b> sectors as well as with individual people.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  this will <b>be</b> in <b>collaboration</b> <b>between</b> <b>public</b> <b>and</b> <b>private</b> players.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> consultation process <b>and</b> <b>the</b> expert forums found that there is <b>a</b> strong need for cooperation <b>between</b> <b>the</b> <b>public</b> <b>and</b> <b>the</b> <b>private</b> <b>sector</b> in this area.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> signature projects will <b>be</b> based <b>on</b> <b>a</b> <b>public</b> operating task, in which <b>a</b> solution with artificial intelligence that can provide better services for citizens has been developed in <b>collaboration</b> <b>between</b> <b>the</b> <b>public</b> <b>sector</b> <b>and</b> <b>the</b> <b>private</b> sector.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> language resource will build <b>on</b> existing initiatives in <b>the</b> <b>public</b> <b>sector</b> <b>and</b> <b>private</b> <b>sector</b> as well as in research communities.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>a</b> significant share of known country-specific initiatives combine <b>the</b> expertise, objectives <b>and</b> impact of <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors in one way <b>or</b> another.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  sweden needs strong <b>collaboration</b> <b>between</b> business, <b>the</b> <b>public</b> <b>sector</b> <b>and</b> research in</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> follow-up will take into account <b>the</b> differences <b>between</b> <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>and</b> china, <b>and</b> it is clear that there is insufficient investment in research <b>and</b> development by both <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors, <b>and</b> that it is necessary for both <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors <b>to</b> develop <b>a</b> research <b>and</b> development environment.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  strengthen connections <b>between</b> academia <b>and</b> industry .</p><hr><p style=\"font-family:verdana; font-size:110%;\">  research results must <b>be</b> easy for both <b>the</b> <b>public</b> <b>and</b> <b>private</b> sectors <b>to</b> utilise, which will require investments in cooperation <b>between</b> companies <b>and</b> research institutes.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  this evolution requires re- <b>or</b> up-skilling of <b>the</b> workforce, which hinges upon <b>the</b> commitment of both <b>public</b> <b>and</b> <b>private</b> institutions.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> national research consortium depends <b>on</b> cross-disciplinary research, i.e. close cooperation with external stakeholders from <b>the</b> <b>public</b> sector, civil society <b>and</b> <b>the</b> business community, including <b>the</b> social partners, <b>and</b> other user groups, starting as early as during <b>the</b> research <b>and</b> development rd process <b>and</b> informing <b>the</b> funding programme as well</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>a</b> incubation hubs specifically for ai startups in <b>collaboration</b> with state governments <b>and</b> <b>private</b> <b>sector</b> stakeholders</p><hr><p style=\"font-family:verdana; font-size:110%;\">  <b>the</b> studies will <b>be</b> realised by using <b>the</b> experiences <b>and</b> best practices of pioneering companies <b>and</b> in cooperation with <b>the</b> <b>public</b> sector.</p><hr><p style=\"font-family:verdana; font-size:110%;\">  this applies <b>to</b> companies <b>and</b> <b>the</b> <b>public</b> sector, as well as individual citizens.</p><hr>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "results_returned = \"20\" #@param [1, 2, 3]\n",
    "\n",
    "output =\"\"\n",
    "for i,j in cosine_similarities.nlargest(int(results_returned)).iteritems():\n",
    "  output +='<p style=\"font-family:verdana; font-size:110%;\"> '\n",
    "  for i in sentences[i].split():\n",
    "    if i.lower() in search_term:\n",
    "      output += \" <b>\"+str(i)+\"</b>\"\n",
    "    else:\n",
    "      output += \" \"+str(i)\n",
    "  output += \"</p><hr>\"\n",
    "    \n",
    "output = '<h3>Results:</h3>'+output\n",
    "display(HTML(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split in batches of 500\n",
    "sentences_chunks = [sentences[i:i+500] for i in range(0,len(sentences),500)]\n",
    "\n",
    "# Extract ELMo embeddings\n",
    "sentences_upper = [y.upper() for x in sentences_chunks for y in x]\n",
    "\n",
    "# # concentrate ELMo embeddings\n",
    "# #flatten the lists\n",
    "# sentences_new = [y for x in sentences_upper for y in x]\n",
    "\n",
    "for x in [1,2,3,4,5]: #stupid way for fun\n",
    "    i = np.random.randint(0,len(sentences))\n",
    "    print(sentences[i])\n",
    "    print(sentences_upper[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sentences_upper)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:brainwaves]",
   "language": "python",
   "name": "conda-env-brainwaves-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
